{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_price_data():\n",
    "    #tickers_list = ['JPM', 'COST', 'IBM', 'HD', 'ARWR']\n",
    "    tickers_list = ['GOOG','AMD','META']\n",
    "\n",
    "# Store multiple result sets.\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    full_price_history = []\n",
    "\n",
    "    for ticker in tickers_list:\n",
    "        price_history = yf.Ticker(ticker).history(period='max', start='2023-01-02', end=end_date, interval='1d')\n",
    "\n",
    "        for index, row in price_history.iterrows():\n",
    "            row_data = row.to_dict()\n",
    "            row_data['symbol'] = ticker\n",
    "            row_data['datetime'] = index.strftime('%Y-%m-%d')  # Convert Pandas Timestamp to datetime string\n",
    "            full_price_history.append(row_data)\n",
    "\n",
    "\n",
    "    price_data = pd.DataFrame(full_price_history)\n",
    "    \n",
    "    \n",
    "    price_data_ro = price_data\n",
    "    price_data = price_data_ro[['datetime', 'symbol', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']] # rearrange column here\n",
    "    price_data.to_csv('inital_price_data.csv', index=False)\n",
    "    price_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./data/inital_price_data.csv'):\n",
    "    \n",
    "    # Load the data\n",
    "    price_data = pd.read_csv('inital_price_data.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Grab the data and store it.\n",
    "    grab_price_data()\n",
    "\n",
    "    # Load the data\n",
    "    price_data = pd.read_csv('inital_price_data.csv')\n",
    "\n",
    "# Display the head before moving on.\n",
    "price_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_price_change():\n",
    "    # Sort the data by symbol and datetime\n",
    "    price_data.sort_values(by = ['symbol','datetime'], inplace = True)\n",
    "\n",
    "    # calculate the change in price\n",
    "    price_data['change_in_price'] = price_data['Close'].diff()\n",
    "\n",
    "    return price_data.head()\n",
    "\n",
    "calculate_price_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_price_change2():\n",
    "    mask = price_data['symbol'] != price_data['symbol'].shift(1)\n",
    "\n",
    "    # For those rows, let's make the value null\n",
    "    price_data['change_in_price'] = np.where(mask == True, np.nan, price_data['change_in_price'])\n",
    "\n",
    "    # print the rows that have a null value, should only be 5\n",
    "    return price_data[price_data.isna().any(axis = 1)]\n",
    "calculate_price_change2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_df():\n",
    "    # define the number of days out you want to predict\n",
    "    days_out = 30\n",
    "\n",
    "    # Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "    price_data_smoothed = price_data.groupby(['symbol'])[['Close','Low','High','Open','Volume']].transform(lambda x: x.ewm(span = days_out).mean())\n",
    "\n",
    "    # Join the smoothed columns with the symbol and datetime column from the old data frame.\n",
    "    smoothed_df = pd.concat([price_data[['symbol','datetime']], price_data_smoothed], axis=1, sort=False)\n",
    "\n",
    "    return smoothed_df\n",
    "\n",
    "smoothed_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_flag():\n",
    "    days_out = 30\n",
    "\n",
    "    # create a new column that will house the flag, and for each group calculate the diff compared to 30 days ago. Then use Numpy to define the sign.\n",
    "    smoothed_df['Signal_Flag'] = smoothed_df.groupby('symbol')['Close'].transform(lambda x : np.sign(x.diff(days_out)))\n",
    "\n",
    "    # print the first 50 rows\n",
    "    return smoothed_df.head(50)\n",
    "\n",
    "signal_flag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RSI():\n",
    "    # Calculate the 14 day RSI\n",
    "    n = 14\n",
    "\n",
    "    # First make a copy of the data frame twice\n",
    "    up_df, down_df = price_data[['symbol','change_in_price']].copy(), price_data[['symbol','change_in_price']].copy()\n",
    "\n",
    "    # For up days, if the change is less than 0 set to 0.\n",
    "    up_df.loc['change_in_price'] = up_df.loc[(up_df['change_in_price'] < 0), 'change_in_price'] = 0\n",
    "\n",
    "    # For down days, if the change is greater than 0 set to 0.\n",
    "    down_df.loc['change_in_price'] = down_df.loc[(down_df['change_in_price'] > 0), 'change_in_price'] = 0\n",
    "\n",
    "    # We need change in price to be absolute.\n",
    "    down_df['change_in_price'] = down_df['change_in_price'].abs()\n",
    "\n",
    "    # Calculate the EWMA (Exponential Weighted Moving Average), meaning older values are given less weight compared to newer values.\n",
    "    ewma_up = up_df.groupby('symbol')['change_in_price'].transform(lambda x: x.ewm(span = n).mean())\n",
    "    ewma_down = down_df.groupby('symbol')['change_in_price'].transform(lambda x: x.ewm(span = n).mean())\n",
    "\n",
    "    # Calculate the Relative Strength\n",
    "    relative_strength = ewma_up / ewma_down\n",
    "\n",
    "    # Calculate the Relative Strength Index\n",
    "    relative_strength_index = 100.0 - (100.0 / (1.0 + relative_strength))\n",
    "\n",
    "    # Add the info to the data frame.\n",
    "    price_data['down_days'] = down_df['change_in_price']\n",
    "    price_data['up_days'] = up_df['change_in_price']\n",
    "    price_data['RSI'] = relative_strength_index\n",
    "\n",
    "    # Display the head.\n",
    "    return price_data.head(30)\n",
    "\n",
    "calculate_RSI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Stoc_Osc():\n",
    "    # Calculate the Stochastic Oscillator\n",
    "    n = 14\n",
    "\n",
    "    # Make a copy of the high and low column.\n",
    "    low_14, high_14 = price_data[['symbol','Low']].copy(), price_data[['symbol','High']].copy()\n",
    "\n",
    "    # Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "    low_14 = low_14.groupby('symbol')['Low'].transform(lambda x: x.rolling(window = n).min())\n",
    "    high_14 = high_14.groupby('symbol')['High'].transform(lambda x: x.rolling(window = n).max())\n",
    "\n",
    "    # Calculate the Stochastic Oscillator.\n",
    "    k_percent = 100 * ((price_data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "    # Add the info to the data frame.\n",
    "    price_data['low_14'] = low_14\n",
    "    price_data['high_14'] = high_14\n",
    "    price_data['k_percent'] = k_percent\n",
    "\n",
    "    # Display the head.\n",
    "    return price_data.head(30)\n",
    "calculate_Stoc_Osc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_williams_R():\n",
    "    # Calculate the Williams %R\n",
    "    n = 14\n",
    "\n",
    "    # Make a copy of the high and low column.\n",
    "    low_14, high_14 = price_data[['symbol','Low']].copy(), price_data[['symbol','High']].copy()\n",
    "\n",
    "    # Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "    low_14 = low_14.groupby('symbol')['Low'].transform(lambda x: x.rolling(window = n).min())\n",
    "    high_14 = high_14.groupby('symbol')['High'].transform(lambda x: x.rolling(window = n).max())\n",
    "\n",
    "    # Calculate William %R indicator.\n",
    "    r_percent = ((high_14 - price_data['Close']) / (high_14 - low_14)) * - 100\n",
    "\n",
    "    # Add the info to the data frame.\n",
    "    price_data['r_percent'] = r_percent\n",
    "\n",
    "    # Display the head.\n",
    "    return price_data.head(30)\n",
    "\n",
    "calculate_williams_R()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MACD():\n",
    "    # Calculate the MACD\n",
    "    ema_26 = price_data.groupby('symbol')['Close'].transform(lambda x: x.ewm(span = 26).mean())\n",
    "    ema_12 = price_data.groupby('symbol')['Close'].transform(lambda x: x.ewm(span = 12).mean())\n",
    "    macd = ema_12 - ema_26\n",
    "\n",
    "    # Calculate the EMA\n",
    "    ema_9_macd = macd.ewm(span = 9).mean()\n",
    "\n",
    "    # Store the data in the data frame.\n",
    "    price_data['MACD'] = macd\n",
    "    price_data['MACD_EMA'] = ema_9_macd\n",
    "\n",
    "    # Print the head.\n",
    "    return price_data.head(30)\n",
    "calculate_MACD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_price_rate_of_change():\n",
    "# Calculate the Price Rate of Change\n",
    "    n = 9\n",
    "\n",
    "    # Calculate the Rate of Change in the Price, and store it in the Data Frame.\n",
    "    price_data['Price_Rate_Of_Change'] = price_data.groupby('symbol')['Close'].transform(lambda x: x.pct_change(periods = n))\n",
    "\n",
    "    # Print the first 30 rows\n",
    "    return price_data.head(30)\n",
    "\n",
    "calculate_price_rate_of_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def obv(group):\n",
    "    \n",
    "    # Grab the volume and close column.\n",
    "    volume = group['Volume']\n",
    "    change = group['Close'].diff()\n",
    "\n",
    "    # intialize the previous OBV\n",
    "    prev_obv = 0\n",
    "    obv_values = []\n",
    "\n",
    "    # calculate the On Balance Volume\n",
    "    for i, j in zip(change, volume):\n",
    "\n",
    "        if i > 0:\n",
    "            current_obv = prev_obv + j\n",
    "        elif i < 0:\n",
    "            current_obv = prev_obv - j\n",
    "        else:\n",
    "            current_obv = prev_obv\n",
    "\n",
    "        # OBV.append(current_OBV)\n",
    "        prev_obv = current_obv\n",
    "        obv_values.append(current_obv)\n",
    "    \n",
    "    # Return a panda series.\n",
    "    return pd.Series(obv_values, index = group.index)\n",
    "        \n",
    "def calculate_obv():\n",
    "# apply the function to each group\n",
    "    obv_groups = price_data.groupby('symbol').apply(obv)\n",
    "\n",
    "    # add to the data frame, but drop the old index, before adding it.\n",
    "    price_data['On Balance Volume'] = obv_groups.reset_index(level=0, drop=True)\n",
    "\n",
    "    # display the data frame.\n",
    "    return price_data.head(30)\n",
    "calculate_obv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    In this case, let's create an output column that will be 1 if the closing price at time 't' is greater than 't-1' and 0 otherwise.\n",
    "    In other words, if the today's closing price is greater than yesterday's closing price it would be 1.\n",
    "'''\n",
    "\n",
    "# Create a column we wish to predict\n",
    "def calculate_prediction():\n",
    "    \n",
    "# Group by the `Symbol` column, then grab the `Close` column.\n",
    "    close_groups = price_data.groupby('symbol')['Close']\n",
    "\n",
    "    # Apply the lambda function which will return -1.0 for down, 1.0 for up and 0.0 for no change.\n",
    "    close_groups = close_groups.transform(lambda x : np.sign(x.diff()))\n",
    "\n",
    "    # add the data to the main dataframe.\n",
    "    price_data['Prediction'] = close_groups\n",
    "\n",
    "    # for simplicity in later sections I'm going to make a change to our prediction column. To keep this as a binary classifier I'll change flat days and consider them up days.\n",
    "    price_data.loc[price_data['Prediction'] == 0.0] = 1.0\n",
    "\n",
    "    # print the head\n",
    "    return price_data.head(50)\n",
    "    # OPTIONAL CODE: Dump the data frame to a CSV file to examine the data yourself.\n",
    "    # price_data.to_csv('final_metrics.csv')\n",
    "calculate_prediction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan():\n",
    "    print('Before NaN Drop we have {} rows and {} columns'.format(price_data.shape[0], price_data.shape[1]))\n",
    "\n",
    "    # Any row that has a `NaN` value will be dropped.\n",
    "    price_data = price_data.dropna()\n",
    "\n",
    "    # Display how much we have left now.\n",
    "    print('After NaN Drop we have {} rows and {} columns'.format(price_data.shape[0], price_data.shape[1]))\n",
    "\n",
    "    # Print the head.\n",
    "    return price_data.head()\n",
    "drop_nan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data.to_csv('./price_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grab our X & Y Columns.\n",
    "X_Cols = price_data[['RSI','k_percent','r_percent','Price_Rate_Of_Change','MACD','On Balance Volume']]\n",
    "Y_Cols = price_data['Prediction']\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Cols, Y_Cols, random_state = 0)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rand_frst_clf = RandomForestClassifier(n_estimators = 100, oob_score = True, criterion = \"gini\", random_state = 0)\n",
    "\n",
    "# Fit the data to the model\n",
    "rand_frst_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rand_frst_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the Accuracy of our Model.\n",
    "print('Correct Prediction (%): ', accuracy_score(y_test, rand_frst_clf.predict(X_test), normalize = True) * 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the traget names\n",
    "target_names = ['Down Day', 'Up Day']\n",
    "\n",
    "# Build a classifcation report\n",
    "report = classification_report(y_true = y_test, y_pred = y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "# Add it to a data frame, transpose it for readability.\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "rf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negatives = rf_matrix[0][0]\n",
    "false_negatives = rf_matrix[1][0]\n",
    "true_positives = rf_matrix[1][1]\n",
    "false_positives = rf_matrix[0][1]\n",
    "\n",
    "accuracy = (true_negatives + true_positives) / (true_negatives + true_positives + false_negatives + false_positives)\n",
    "percision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "print('Accuracy: {}'.format(float(accuracy)))\n",
    "print('Percision: {}'.format(float(percision)))\n",
    "print('Recall: {}'.format(float(recall)))\n",
    "print('Specificity: {}'.format(float(specificity)))\n",
    "disp = ConfusionMatrixDisplay(rand_frst_clf, X_test, y_test, display_labels = ['Down Day', 'Up Day'], normalize= 'true', cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Confusion Matrix - Normalized')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_imp = pd.Series(rand_frst_clf.feature_importances_, index=X_Cols.columns).sort_values(ascending=False)\n",
    "feature_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store the values in a list to plot.\n",
    "x_values = list(range(len(rand_frst_clf.feature_importances_)))\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(feature_imp.values)\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin = 0, xmax = len(feature_imp), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, feature_imp.index, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.title('Random Forest: Feature Importance Graph')\n",
    "rfc_disp = RocCurveDisplay(rand_frst_clf, X_test, y_test, alpha = 0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_disp = RocCurveDisplay(rand_frst_clf, X_test, y_test, alpha = 0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Random Forest Out-Of-Bag Error Score: {}'.format(rand_frst_clf.oob_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "# Number of trees is not a parameter that should be tuned, but just set large enough usually. There is no risk of overfitting in random forest with growing number of # trees, as they are trained independently from each other. \n",
    "n_estimators = list(range(200, 2000, 200))\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', None, 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "# Max depth is a parameter that most of the times should be set as high as possible, but possibly better performance can be achieved by setting it lower.\n",
    "max_depth = list(range(10, 110, 10))\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "# Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Too high values can also lead to # under-fitting hence depending on the level of underfitting or overfitting, you can tune the values for min_samples_split.\n",
    "min_samples_split = [2, 5, 10, 20, 30, 40]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 7, 12, 14, 16 ,20]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# New Random Forest Classifier to house optimal parameters\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Specfiy the details of our Randomized Search\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "# With the new Random Classifier trained we can proceed to our regular steps, prediction.\n",
    "rf_random.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "    ACCURACY\n",
    "'''\n",
    "# Once the predictions have been made, then grab the accuracy score.\n",
    "print('Correct Prediction (%): ', accuracy_score(y_test, rf_random.predict(X_test), normalize = True) * 100.0)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    CLASSIFICATION REPORT\n",
    "'''\n",
    "# Define the traget names\n",
    "target_names = ['Down Day', 'Up Day']\n",
    "\n",
    "# Build a classifcation report\n",
    "report = classification_report(y_true = y_test, y_pred = y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "# Add it to a data frame, transpose it for readability.\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "display(report_df)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "    FEATURE IMPORTANCE\n",
    "'''\n",
    "# Calculate feature importance and store in pandas series\n",
    "feature_imp = pd.Series(rand_frst_clf.feature_importances_, index=X_Cols.columns).sort_values(ascending=False)\n",
    "display(feature_imp)# With the new Random Classifier trained we can proceed to our regular steps, prediction.\n",
    "rf_random.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "    ACCURACY\n",
    "'''\n",
    "# Once the predictions have been made, then grab the accuracy score.\n",
    "print('Correct Prediction (%): ', accuracy_score(y_test, rf_random.predict(X_test), normalize = True) * 100.0)\n",
    "\n",
    "\n",
    "'''\n",
    "    CLASSIFICATION REPORT\n",
    "'''\n",
    "# Define the traget names\n",
    "target_names = ['Down Day', 'Up Day']\n",
    "\n",
    "# Build a classifcation report\n",
    "report = classification_report(y_true = y_test, y_pred = y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "# Add it to a data frame, transpose it for readability.\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "display(report_df)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "    FEATURE IMPORTANCE\n",
    "'''\n",
    "# Calculate feature importance and store in pandas series\n",
    "feature_imp = pd.Series(rand_frst_clf.feature_importances_, index=X_Cols.columns).sort_values(ascending=False)\n",
    "display(feature_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    ROC CURVE\n",
    "'''\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create an ROC Curve plot.\n",
    "rfc_disp = RocCurveDisplay(rand_frst_clf, X_test, y_test, alpha = 0.8, name='ROC Curve', lw=1, ax=ax)\n",
    "\n",
    "# Add our Chance Line\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "# Make it look pretty.\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=\"ROC Curve Random Forest\")\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# # Save the model\n",
    "# joblib.dump(rand_frst_clf, 'random_forest_model.pkl')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the new data\n",
    "new_data = pd.read_csv('price_2.csv') \n",
    "\n",
    "# Grab the new features\n",
    "new_features = new_data[['RSI', 'k_percent', 'r_percent', 'Price_Rate_Of_Change', 'MACD', 'On Balance Volume']] \n",
    "\n",
    "# Make a prediction\n",
    "new_data['Model_Prediction'] = loaded_model.predict(new_features)\n",
    "\n",
    "# Print the first 50 rows\n",
    "print(new_data[['datetime', 'symbol', 'Close', 'Prediction', 'Model_Prediction']].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(new_data['Prediction'], new_data['Model_Prediction'])\n",
    "print('Accuracy: {}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_trade():\n",
    "    # Grab the last row of the data frame\n",
    "    last_row = new_data.iloc[-1]\n",
    "    print(last_row)\n",
    "\n",
    "    # If the prediction is 1, then buy\n",
    "    if last_row['Model_Prediction'] == 1:\n",
    "        print('Buy Signal')\n",
    "    \n",
    "    # If the prediction is 0, then hold\n",
    "    elif last_row['Model_Prediction'] == 0:\n",
    "        print('Hold Signal')\n",
    "        \n",
    "    # Otherwise sell\n",
    "    else:\n",
    "        print('Sell Signal')\n",
    "\n",
    "execute_trade()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
